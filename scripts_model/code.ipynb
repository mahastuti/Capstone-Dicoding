{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9dccdd",
   "metadata": {},
   "source": [
    "> LOAD & BASIC CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bccca412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nalin\\AppData\\Local\\Temp\\ipykernel_3300\\3456374715.py:5: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/skill_builder_data.csv', encoding='latin1')\n",
      "c:\\Users\\nalin\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv('data/skill_builder_data.csv', encoding='latin1')\n",
    "\n",
    "df = df.copy()\n",
    "df['user_id'] = df['user_id'].astype(str)\n",
    "df['problem_id'] = df['problem_id'].astype(str)\n",
    "df['skill_id'] = df['skill_id'].fillna('unknown').astype(str)\n",
    "df['correct'] = pd.to_numeric(df['correct'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "df['ms_first_response'] = pd.to_numeric(df.get('ms_first_response', 0), errors='coerce').fillna(0)\n",
    "df['ms_first_response'] = df['ms_first_response'].clip(upper=600000)\n",
    "df['log_response_time'] = np.log1p(df['ms_first_response'])\n",
    "\n",
    "for c in ['hint_count','hint_total','attempt_count','opportunity']:\n",
    "    df[c] = pd.to_numeric(df.get(c,0), errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "df = df.sort_values(['user_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0c30fb",
   "metadata": {},
   "source": [
    "> FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e1544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# past correct\n",
    "df['past_correct_skill'] = (\n",
    "    df.groupby(['user_id','skill_id'])['correct']\n",
    "    .transform(lambda s: s.shift().fillna(0).cumsum())\n",
    ")\n",
    "\n",
    "# attempts\n",
    "df['attempts_skill'] = df.groupby(['user_id','skill_id']).cumcount()\n",
    "\n",
    "# success rate\n",
    "df['success_rate_skill'] = df['past_correct_skill'] / df['attempts_skill'].replace(0, np.nan)\n",
    "df['success_rate_skill'] = df['success_rate_skill'].fillna(0)\n",
    "\n",
    "# streak\n",
    "def prev_streak(s):\n",
    "    prev = s.shift().fillna(0).astype(int).to_numpy()\n",
    "    out = np.zeros(len(prev), dtype=int)\n",
    "    cur = 0\n",
    "    for i, v in enumerate(prev):\n",
    "        cur = cur + 1 if v == 1 else 0\n",
    "        out[i] = cur\n",
    "    return out\n",
    "\n",
    "df['prev_streak_skill'] = df.groupby(['user_id','skill_id'])['correct'].transform(prev_streak)\n",
    "\n",
    "\n",
    "# difficulty estimation\n",
    "prob_stats = df.groupby('problem_id')['correct'].mean()\n",
    "df['difficulty_est'] = 1 - df['problem_id'].map(prob_stats).fillna(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5136e80",
   "metadata": {},
   "source": [
    "> LABEL ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = ['skill_id', 'problem_id']\n",
    "encoders = {}\n",
    "\n",
    "for c in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[c] = le.fit_transform(df[c].astype(str))\n",
    "    encoders[c] = le\n",
    "\n",
    "joblib.dump(encoders, 'label_encoders.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca35ad",
   "metadata": {},
   "source": [
    "> FEATURE SELECTION (Mutual Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b7794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "candidate_feats = [\n",
    "    'skill_id','problem_id',\n",
    "    'past_correct_skill','attempts_skill','success_rate_skill','prev_streak_skill',\n",
    "    'hint_count','hint_total','attempt_count',\n",
    "    'log_response_time','difficulty_est','opportunity'\n",
    "]\n",
    "\n",
    "X = df[candidate_feats].fillna(0)\n",
    "y = df['correct']\n",
    "\n",
    "mi = mutual_info_classif(X, y, random_state=42)\n",
    "mi_series = pd.Series(mi, index=candidate_feats).sort_values(ascending=False)\n",
    "\n",
    "top_features = mi_series.index[:10].tolist()\n",
    "joblib.dump(top_features, 'selected_features.joblib')\n",
    "\n",
    "print(\"Selected features:\", top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15a33f",
   "metadata": {},
   "source": [
    "> TEMPORAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea0158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_split(df, ratio=0.1):\n",
    "    train_idx, test_idx = [], []\n",
    "    for uid, g in df.groupby('user_id'):\n",
    "        n = len(g)\n",
    "        n_test = max(1, int(np.ceil(n * ratio)))\n",
    "        train_idx += list(g.index[:-n_test])\n",
    "        test_idx  += list(g.index[-n_test:])\n",
    "    return df.loc[train_idx], df.loc[test_idx]\n",
    "\n",
    "train_df, test_df = temporal_split(df)\n",
    "\n",
    "X_train = train_df[top_features]\n",
    "y_train = train_df['correct']\n",
    "X_test  = test_df[top_features]\n",
    "y_test  = test_df['correct']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8014eaf0",
   "metadata": {},
   "source": [
    "> HYPERPARAMETER TUNING (RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "param_grid = {\n",
    "    \"num_leaves\": [31, 50, 70],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [200, 500, 800],\n",
    "    \"max_depth\": [-1, 5, 10]\n",
    "}\n",
    "\n",
    "base_model = LGBMClassifier(random_state=42)\n",
    "\n",
    "tuner = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    scoring=\"f1\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "tuner.fit(X_train, y_train)\n",
    "\n",
    "best_model = tuner.best_estimator_\n",
    "print(\"Best params →\", tuner.best_params_)\n",
    "\n",
    "joblib.dump(best_model, \"model/lgb_best.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddbe26e",
   "metadata": {},
   "source": [
    "> FINAL EVALUATION (TEST SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8215cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Prediksi ---\n",
    "proba = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# --- Metrics ---\n",
    "auc_score = roc_auc_score(y_test, proba)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"AUC:\", auc_score)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"viridis\")   # <-- 4 warna (gradasi hijau-biru)\n",
    "plt.title(\"Confusion Matrix (4-color heatmap)\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dcf44f",
   "metadata": {},
   "source": [
    "> SAVE PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = {\n",
    "    \"encoders\": encoders,\n",
    "    \"selected_features\": top_features,\n",
    "    \"model\": best_model\n",
    "}\n",
    "\n",
    "joblib.dump(pipeline, \"assist_model_pipeline.joblib\")\n",
    "print(\"Saved → assist_model_pipeline.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
